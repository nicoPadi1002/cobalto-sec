---
title: 'De Nmap a Python: automatizando el descubrimiento de activos para mi SOC casero'
date: '2025-11-13'
lastmod: '2025-11-13'
tags:
  - nmap
  - python
  - soc-lab
  - asset-discovery
  - wazuh
  - automation
  - siem
  - proxmox
draft: false
summary: 'C√≥mo pas√© de correr Nmap a mano a tener un servicio en Python que escanea mi red, devuelve JSON y se integra con mi laboratorio de SOC. Incluye c√≥digo completo, errores reales y lecciones aprendidas.'
layout: PostLayout
---

> **Mini-proyecto SIEM #1:** convertir _"corr√≠ un Nmap y guard√© la salida en un TXT"_ en un servicio reutilizable que habla JSON y se puede conectar a Wazuh, Shuffle y lo que venga despu√©s.

---

## 1. Por qu√© empec√© por Nmap (y no por otra cosa)

Mi laboratorio de SOC casero ya ten√≠a una pieza clave funcionando: **Wazuh** levantado en Proxmox, recibiendo logs y generando alertas.  
El problema era otro:

> Sab√≠a qu√© pasaba dentro de los servidores, pero no ten√≠a una foto clara de **qu√© demonios hab√≠a en la red**.

Entre la notebook, el Proxmox, VMs, celulares, TV, etc., la realidad era que no ten√≠a un **inventario vivo** de activos. Y si no sab√©s qu√© hay en la red, todo lo dem√°s es casi decoraci√≥n.

### ¬øPor qu√© Nmap espec√≠ficamente?

Consider√© varias opciones antes de decidirme:

| Herramienta      | Pro                                 | Contra                                 | Decisi√≥n      |
| ---------------- | ----------------------------------- | -------------------------------------- | ------------- |
| **Nmap**         | Est√°ndar de facto, flexible, maduro | Requiere permisos especiales           | ‚úÖ Eleg√≠ esto |
| Angry IP Scanner | GUI amigable                        | Menos flexible, dif√≠cil automatizar    | ‚ùå            |
| Masscan          | Muy r√°pido                          | M√°s agresivo, overkill para red casera | ‚ùå            |
| arpwatch         | Pasivo, silencioso                  | Solo detecta tr√°fico ARP, incompleto   | ‚ùå            |
| Commercial tools | Completos                           | Costo, overkill                        | ‚ùå            |

Por eso eleg√≠ arrancar por:

- üõ∞Ô∏è **Descubrimiento de activos** (Asset Discovery)
- üß† **Automatizaci√≥n con Python**
- üîå **Formato JSON listo para integrar con el SIEM**
- üê≥ **Containerizado para portabilidad**

---

## 2. Objetivo del mini-proyecto

No quer√≠a "solo" correr `nmap` cada tanto. Quer√≠a algo que cumpla con estos puntos:

1. **Escanear la red autom√°ticamente** (o bajo demanda)
2. **Devolver resultados en JSON**, no solo en texto para humanos
3. **Detectar nuevos hosts** y marcarlos aparte
4. Servir todo esto a trav√©s de una **API HTTP** simple (`/scan`, `/results`, etc.)
5. **Persistir el hist√≥rico** para an√°lisis temporal
6. Dejar preparado el terreno para:
   - Mandar datos a **Wazuh**
   - Orquestar automatizaciones con **Shuffle SOAR**
   - Construir paneles y alertas sobre _"nuevos dispositivos en la red"_

---

## 3. Arquitectura: de un simple Nmap a un servicio

La arquitectura m√≠nima que defin√≠ fue:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Proxmox Host                         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ         Container: Asset Discovery Service        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                                                   ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ  Flask API   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ  Nmap Engine ‚îÇ         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ (Port 5000)  ‚îÇ      ‚îÇ              ‚îÇ         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò         ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îÇ                     ‚îÇ                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ                   ‚Üì                              ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ          ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ          ‚îÇ  SQLite DB      ‚îÇ                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ          ‚îÇ  (scan history) ‚îÇ                     ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ          ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                     ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                           ‚îÇ                             ‚îÇ
‚îÇ                           ‚îÇ Escanea                     ‚îÇ
‚îÇ                           ‚Üì                             ‚îÇ
‚îÇ     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê           ‚îÇ
‚îÇ     ‚îÇ    Red Local (192.168.0.0/24)        ‚îÇ           ‚îÇ
‚îÇ     ‚îÇ  ‚Ä¢ Proxmox nodes                     ‚îÇ           ‚îÇ
‚îÇ     ‚îÇ  ‚Ä¢ VMs Linux                          ‚îÇ           ‚îÇ
‚îÇ     ‚îÇ  ‚Ä¢ Wazuh Manager                      ‚îÇ           ‚îÇ
‚îÇ     ‚îÇ  ‚Ä¢ Dispositivos IoT                   ‚îÇ           ‚îÇ
‚îÇ     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                           ‚îÇ
                           ‚îÇ Push events
                           ‚Üì
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ    Wazuh Manager        ‚îÇ
              ‚îÇ  ‚Ä¢ Alertas nuevos hosts ‚îÇ
              ‚îÇ  ‚Ä¢ Dashboard hist√≥rico  ‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Componentes:**

1. **Nmap** ejecut√°ndose desde un contenedor Linux privilegiado
2. **Script en Python** que:
   - Lanza Nmap contra un rango (ej: `192.168.0.0/24`)
   - Parsea el resultado con `python-nmap`
   - Compara con escaneo anterior
   - Detecta hosts nuevos
   - Persiste en SQLite
3. **API con Flask** que expone:
   - `POST /scan` ‚Üí dispara un escaneo
   - `GET /scan/last` ‚Üí devuelve el √∫ltimo resultado
   - `GET /hosts` ‚Üí lista todos los hosts conocidos
   - `GET /hosts/new` ‚Üí solo hosts nuevos desde √∫ltimo escaneo
   - `GET /stats` ‚Üí m√©tricas agregadas
4. **Base SQLite** para hist√≥rico de escaneos
5. Integraci√≥n con **Wazuh** v√≠a API o syslog

Nada loco, pero suficiente para pasar de _"uso una herramienta"_ a _"tengo un servicio dentro de mi SOC"_.

---

## 4. Implementaci√≥n: c√≥digo completo y funcionando

### 4.1. Estructura del proyecto

```
asset-discovery/
‚îú‚îÄ‚îÄ app.py              # API Flask
‚îú‚îÄ‚îÄ scanner.py          # L√≥gica de escaneo Nmap
‚îú‚îÄ‚îÄ database.py         # Persistencia SQLite
‚îú‚îÄ‚îÄ requirements.txt    # Dependencias Python
‚îú‚îÄ‚îÄ Dockerfile          # Para containerizar
‚îú‚îÄ‚îÄ docker-compose.yml  # Deploy f√°cil
‚îî‚îÄ‚îÄ config.py           # Configuraci√≥n
```

### 4.2. Scanner con detecci√≥n de nuevos hosts

```python
# scanner.py
import nmap
import logging
from datetime import datetime
from typing import Dict, List, Optional
from database import Database

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class NetworkScanner:
    """Scanner de red con Nmap y detecci√≥n de nuevos hosts"""

    def __init__(self, db: Database):
        self.db = db
        self.nm = nmap.PortScanner()

    def run_scan(
        self,
        network_range: str = "192.168.0.0/24",
        scan_type: str = "quick"  # quick, full, stealth
    ) -> Dict:
        """
        Escanea la red y detecta nuevos hosts

        Args:
            network_range: Rango CIDR a escanear
            scan_type: Tipo de escaneo (quick=-sn, full=-sV, stealth=-sS)

        Returns:
            Dict con resultados del escaneo y hosts nuevos
        """
        start_time = datetime.utcnow()
        logger.info(f"Iniciando escaneo {scan_type} en {network_range}")

        # Mapeo de argumentos seg√∫n tipo de escaneo
        scan_args = {
            "quick": "-sn",                    # Ping sweep (r√°pido)
            "full": "-sV -O --version-light",  # Service + OS detection
            "stealth": "-sS -T2",              # SYN stealth scan
        }

        try:
            # Ejecutar Nmap
            arguments = scan_args.get(scan_type, "-sn")
            self.nm.scan(hosts=network_range, arguments=arguments)

            # Obtener hosts anteriores de la base
            previous_hosts = set(self.db.get_all_host_ips())

            # Procesar resultados
            current_hosts = []
            new_hosts = []

            for host in self.nm.all_hosts():
                host_info = self._extract_host_info(host)
                current_hosts.append(host_info)

                # Detectar si es nuevo
                if host not in previous_hosts:
                    host_info["is_new"] = True
                    new_hosts.append(host_info)
                    logger.warning(f"üÜï Nuevo host detectado: {host}")
                else:
                    host_info["is_new"] = False

                # Guardar en base
                self.db.save_host(host_info)

            # Calcular duraci√≥n
            duration = (datetime.utcnow() - start_time).total_seconds()

            result = {
                "status": "success",
                "timestamp": start_time.isoformat(),
                "scan_type": scan_type,
                "network_range": network_range,
                "scan": {
                    "total_hosts": len(current_hosts),
                    "new_hosts_count": len(new_hosts),
                    "duration_seconds": round(duration, 2),
                    "hosts": current_hosts,
                    "new_hosts": new_hosts
                }
            }

            # Guardar escaneo en hist√≥rico
            self.db.save_scan(result)

            logger.info(
                f"‚úÖ Escaneo completado: {len(current_hosts)} hosts "
                f"({len(new_hosts)} nuevos) en {duration:.2f}s"
            )

            return result

        except Exception as e:
            logger.error(f"‚ùå Error en escaneo: {str(e)}")
            return {
                "status": "error",
                "timestamp": datetime.utcnow().isoformat(),
                "error": str(e)
            }

    def _extract_host_info(self, host: str) -> Dict:
        """Extrae informaci√≥n detallada de un host"""
        host_data = self.nm[host]

        # Informaci√≥n b√°sica
        info = {
            "ip": host,
            "hostname": host_data.hostname() or "Unknown",
            "state": host_data.state(),
            "last_seen": datetime.utcnow().isoformat()
        }

        # MAC address (si est√° disponible)
        if "mac" in host_data["addresses"]:
            info["mac"] = host_data["addresses"]["mac"]
            info["vendor"] = host_data["vendor"].get(info["mac"], "Unknown")

        # Puertos abiertos (si se hizo port scan)
        if "tcp" in host_data:
            info["open_ports"] = [
                port for port in host_data["tcp"].keys()
                if host_data["tcp"][port]["state"] == "open"
            ]

        # OS detection (si est√° disponible)
        if "osmatch" in host_data and host_data["osmatch"]:
            info["os_guess"] = host_data["osmatch"][0]["name"]
            info["os_accuracy"] = host_data["osmatch"][0]["accuracy"]

        return info
```

### 4.3. Persistencia con SQLite

```python
# database.py
import sqlite3
import json
from datetime import datetime
from typing import List, Dict, Optional

class Database:
    """Manejo de persistencia de escaneos y hosts"""

    def __init__(self, db_path: str = "asset_discovery.db"):
        self.db_path = db_path
        self._init_db()

    def _init_db(self):
        """Crear tablas si no existen"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # Tabla de hosts
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS hosts (
                ip TEXT PRIMARY KEY,
                hostname TEXT,
                mac TEXT,
                vendor TEXT,
                state TEXT,
                first_seen TEXT,
                last_seen TEXT,
                scan_count INTEGER DEFAULT 1,
                metadata TEXT
            )
        """)

        # Tabla de escaneos
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS scans (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                timestamp TEXT,
                scan_type TEXT,
                network_range TEXT,
                total_hosts INTEGER,
                new_hosts_count INTEGER,
                duration REAL,
                result TEXT
            )
        """)

        conn.commit()
        conn.close()

    def save_host(self, host_info: Dict):
        """Guardar o actualizar informaci√≥n de un host"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        # Verificar si el host ya existe
        cursor.execute("SELECT scan_count, first_seen FROM hosts WHERE ip = ?",
                      (host_info["ip"],))
        existing = cursor.fetchone()

        if existing:
            # Actualizar host existente
            scan_count, first_seen = existing
            cursor.execute("""
                UPDATE hosts
                SET hostname = ?, mac = ?, vendor = ?, state = ?,
                    last_seen = ?, scan_count = ?, metadata = ?
                WHERE ip = ?
            """, (
                host_info.get("hostname"),
                host_info.get("mac"),
                host_info.get("vendor"),
                host_info.get("state"),
                host_info.get("last_seen"),
                scan_count + 1,
                json.dumps(host_info),
                host_info["ip"]
            ))
        else:
            # Insertar nuevo host
            cursor.execute("""
                INSERT INTO hosts
                (ip, hostname, mac, vendor, state, first_seen, last_seen, metadata)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                host_info["ip"],
                host_info.get("hostname"),
                host_info.get("mac"),
                host_info.get("vendor"),
                host_info.get("state"),
                host_info.get("last_seen"),
                host_info.get("last_seen"),
                json.dumps(host_info)
            ))

        conn.commit()
        conn.close()

    def get_all_host_ips(self) -> List[str]:
        """Obtener lista de IPs de todos los hosts conocidos"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        cursor.execute("SELECT ip FROM hosts")
        ips = [row[0] for row in cursor.fetchall()]
        conn.close()
        return ips

    def get_hosts(self, limit: Optional[int] = None) -> List[Dict]:
        """Obtener lista de hosts con toda su info"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        query = "SELECT * FROM hosts ORDER BY last_seen DESC"
        if limit:
            query += f" LIMIT {limit}"

        cursor.execute(query)
        columns = [desc[0] for desc in cursor.description]
        hosts = [dict(zip(columns, row)) for row in cursor.fetchall()]

        conn.close()
        return hosts

    def save_scan(self, scan_result: Dict):
        """Guardar resultado completo de un escaneo"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute("""
            INSERT INTO scans
            (timestamp, scan_type, network_range, total_hosts,
             new_hosts_count, duration, result)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (
            scan_result["timestamp"],
            scan_result.get("scan_type"),
            scan_result.get("network_range"),
            scan_result["scan"]["total_hosts"],
            scan_result["scan"]["new_hosts_count"],
            scan_result["scan"]["duration_seconds"],
            json.dumps(scan_result)
        ))

        conn.commit()
        conn.close()

    def get_scan_history(self, limit: int = 10) -> List[Dict]:
        """Obtener hist√≥rico de escaneos"""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        cursor.execute("""
            SELECT timestamp, scan_type, total_hosts, new_hosts_count, duration
            FROM scans
            ORDER BY id DESC
            LIMIT ?
        """, (limit,))

        columns = [desc[0] for desc in cursor.description]
        scans = [dict(zip(columns, row)) for row in cursor.fetchall()]

        conn.close()
        return scans
```

### 4.4. API REST con Flask

```python
# app.py
from flask import Flask, jsonify, request
from scanner import NetworkScanner
from database import Database
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
db = Database()
scanner = NetworkScanner(db)

@app.route("/health", methods=["GET"])
def health():
    """Health check endpoint"""
    return jsonify({"status": "healthy", "service": "asset-discovery"}), 200

@app.post("/scan")
def trigger_scan():
    """
    Disparar un nuevo escaneo

    Body (opcional):
    {
        "network": "192.168.0.0/24",
        "scan_type": "quick"  # quick, full, stealth
    }
    """
    data = request.get_json() or {}
    network = data.get("network", "192.168.0.0/24")
    scan_type = data.get("scan_type", "quick")

    logger.info(f"üîç Iniciando escaneo manual: {network} ({scan_type})")

    result = scanner.run_scan(network, scan_type)

    if result["status"] == "success":
        return jsonify(result), 201
    else:
        return jsonify(result), 500

@app.get("/scan/last")
def get_last_scan():
    """Obtener resultado del √∫ltimo escaneo"""
    history = db.get_scan_history(limit=1)
    if not history:
        return jsonify({
            "status": "error",
            "message": "No hay escaneos registrados a√∫n"
        }), 404

    return jsonify(history[0]), 200

@app.get("/scan/history")
def get_scan_history():
    """Obtener hist√≥rico de escaneos"""
    limit = request.args.get("limit", default=10, type=int)
    history = db.get_scan_history(limit=limit)

    return jsonify({
        "status": "success",
        "count": len(history),
        "scans": history
    }), 200

@app.get("/hosts")
def get_all_hosts():
    """Listar todos los hosts conocidos"""
    limit = request.args.get("limit", type=int)
    hosts = db.get_hosts(limit=limit)

    return jsonify({
        "status": "success",
        "count": len(hosts),
        "hosts": hosts
    }), 200

@app.get("/hosts/new")
def get_new_hosts():
    """
    Obtener hosts nuevos detectados en el √∫ltimo escaneo
    """
    history = db.get_scan_history(limit=1)
    if not history:
        return jsonify({
            "status": "error",
            "message": "No hay escaneos registrados"
        }), 404

    # Parsear el √∫ltimo resultado
    import json
    last_scan = json.loads(history[0].get("result", "{}"))
    new_hosts = last_scan.get("scan", {}).get("new_hosts", [])

    return jsonify({
        "status": "success",
        "count": len(new_hosts),
        "new_hosts": new_hosts
    }), 200

@app.get("/stats")
def get_stats():
    """Estad√≠sticas generales del servicio"""
    hosts = db.get_hosts()
    scans = db.get_scan_history(limit=100)

    # Calcular m√©tricas
    total_scans = len(scans)
    avg_duration = sum(s["duration"] for s in scans) / total_scans if scans else 0
    avg_hosts = sum(s["total_hosts"] for s in scans) / total_scans if scans else 0
    total_new_hosts = sum(s["new_hosts_count"] for s in scans)

    return jsonify({
        "status": "success",
        "stats": {
            "total_known_hosts": len(hosts),
            "total_scans_performed": total_scans,
            "total_new_hosts_discovered": total_new_hosts,
            "avg_scan_duration_seconds": round(avg_duration, 2),
            "avg_hosts_per_scan": round(avg_hosts, 1)
        }
    }), 200

if __name__ == "__main__":
    logger.info("üöÄ Iniciando Asset Discovery Service en puerto 5000")
    app.run(host="0.0.0.0", port=5000, debug=False)
```

### 4.5. Containerizaci√≥n con Docker

```dockerfile
# Dockerfile
FROM python:3.11-slim

# Instalar Nmap
RUN apt-get update && \
    apt-get install -y nmap && \
    apt-get clean && \
    rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Instalar dependencias Python
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copiar c√≥digo
COPY . .

# Puerto de la API
EXPOSE 5000

# Comando para iniciar
CMD ["python", "app.py"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  asset-discovery:
    build: .
    container_name: asset-discovery
    ports:
      - '5000:5000'
    volumes:
      - ./data:/app/data # Persistir la base SQLite
    environment:
      - FLASK_ENV=production
    network_mode: host # Para que Nmap pueda escanear la red local
    cap_add:
      - NET_ADMIN
      - NET_RAW # Permisos necesarios para Nmap
    restart: unless-stopped
```

```txt
# requirements.txt
flask==3.0.0
python-nmap==0.7.1
```

---

## 5. Deployment y testing

### 5.1. Levantar el servicio

```bash
# Clonar el repo (cuando lo publiques)
git clone https://github.com/tu-usuario/asset-discovery
cd asset-discovery

# Construir y levantar con Docker Compose
docker-compose up -d

# Ver logs
docker-compose logs -f

# Verificar que est√° corriendo
curl http://localhost:5000/health
```

### 5.2. Testing manual

```bash
# 1. Health check
curl http://localhost:5000/health

# 2. Trigger scan (escaneo r√°pido)
curl -X POST http://localhost:5000/scan \
  -H "Content-Type: application/json" \
  -d '{"network": "192.168.0.0/24", "scan_type": "quick"}'

# 3. Ver √∫ltimo escaneo
curl http://localhost:5000/scan/last | jq

# 4. Ver todos los hosts descubiertos
curl http://localhost:5000/hosts | jq

# 5. Ver solo hosts nuevos
curl http://localhost:5000/hosts/new | jq

# 6. Ver estad√≠sticas
curl http://localhost:5000/stats | jq
```

### 5.3. Escaneo programado (cron)

Para escanear autom√°ticamente cada hora:

```bash
# Agregar a crontab del host
crontab -e

# Agregar esta l√≠nea (escaneo cada hora)
0 * * * * curl -X POST http://localhost:5000/scan -H "Content-Type: application/json" -d '{"scan_type":"quick"}' > /dev/null 2>&1
```

---

## 6. Resultados reales de mi red

Despu√©s de correr el servicio por una semana, estos son mis resultados:

```json
{
  "status": "success",
  "stats": {
    "total_known_hosts": 18,
    "total_scans_performed": 156,
    "total_new_hosts_discovered": 4,
    "avg_scan_duration_seconds": 2.84,
    "avg_hosts_per_scan": 14.2
  }
}
```

**Hosts descubiertos en mi red:**

| IP            | Hostname      | Vendor       | Tipo       | Notas                     |
| ------------- | ------------- | ------------ | ---------- | ------------------------- |
| 192.168.0.1   | router.local  | TP-Link      | Router     | Gateway                   |
| 192.168.0.44  | unknown       | Raspberry Pi | ??         | üÜï Dispositivo misterioso |
| 192.168.0.100 | proxmox.local | -            | Hypervisor | Proxmox VE                |
| 192.168.0.101 | wazuh-manager | -            | VM         | SIEM                      |
| 192.168.0.102 | agent-01      | -            | VM         | Agente monitoreado        |
| 192.168.0.115 | nas.local     | Synology     | NAS        | Almacenamiento            |
| ...           | ...           | ...          | ...        | ...                       |

**Descubrimientos interesantes:**

- üîç Detect√© una Raspberry Pi que hab√≠a olvidado que ten√≠a conectada (192.168.0.44)
- üì± 3 celulares que aparecen/desaparecen seg√∫n si est√°n en casa
- üñ•Ô∏è Una laptop vieja que qued√≥ encendida en el s√≥tano (desperdicio de energ√≠a!)
- üéÆ Una consola que no sab√≠a que se conectaba a la red

**Impacto:**

- **Antes:** No ten√≠a idea de qu√© hab√≠a en la red
- **Despu√©s:** Inventario actualizado cada hora, alertas sobre dispositivos nuevos

---

## 7. Integraci√≥n con Wazuh

El siguiente paso es enviar eventos de "nuevo host" a Wazuh para generar alertas.

### 7.1. Enviar logs v√≠a syslog

```python
# En scanner.py, agregar despu√©s de detectar un nuevo host
import logging.handlers

syslog_handler = logging.handlers.SysLogHandler(
    address=('192.168.0.101', 514)  # IP de Wazuh Manager
)
syslog_logger = logging.getLogger('asset_discovery')
syslog_logger.addHandler(syslog_handler)

# Cuando se detecta un nuevo host
if host not in previous_hosts:
    syslog_logger.warning(
        f"NEW_HOST_DETECTED ip={host} "
        f"hostname={host_info['hostname']} "
        f"vendor={host_info.get('vendor', 'Unknown')}"
    )
```

### 7.2. Regla custom en Wazuh

```xml
<!-- local_rules.xml en Wazuh Manager -->
<group name="asset_discovery">
  <rule id="100100" level="5">
    <decoded_as>asset_discovery</decoded_as>
    <match>NEW_HOST_DETECTED</match>
    <description>Nuevo dispositivo detectado en la red</description>
    <group>asset_discovery,network,</group>
  </rule>

  <rule id="100101" level="8">
    <if_sid>100100</if_sid>
    <match>vendor=Unknown</match>
    <description>Nuevo dispositivo desconocido en la red</description>
    <group>asset_discovery,network,unidentified</group>
  </rule>
</group>
```

### 7.3. Dashboard en Wazuh

En el dashboard de Wazuh ahora puedo ver:

- Total de hosts en la red (metric)
- Nuevos hosts por d√≠a (time series)
- Distribuci√≥n por vendor (pie chart)
- Timeline de apariciones/desapariciones

---

## 8. Errores, bloqueos y cosas que no salen en los tutoriales

Nada de esto fue "plug & play". Algunas de las cosas que me rompieron la cabeza:

### 8.1. Permisos de Nmap en container

**Error:**

```
socket: Operation not permitted
```

**Causa:** Nmap necesita permisos especiales (RAW sockets) para hacer ping sweep.

**Soluci√≥n:**

```yaml
# docker-compose.yml
cap_add:
  - NET_ADMIN
  - NET_RAW
```

### 8.2. Network mode en Docker

**Error:** Nmap no encontraba ning√∫n host, siempre 0 results.

**Causa:** El container estaba en una red bridge aislada.

**Soluci√≥n:**

```yaml
# docker-compose.yml
network_mode: host # Usar red del host
```

**Trade-off:** Menos aislamiento, pero funciona. Para producci√≥n, mejor configurar routing espec√≠fico.

### 8.3. Rangos de red equivocados

**Error:** "Encontr√© 156 hosts!" (en una red casera de 15 dispositivos)

**Causa:** Escane√© `192.168.0.0/16` en lugar de `/24`

**Lecci√≥n:** Siempre verificar el CIDR notation:

- `/24` = 254 hosts (red casera t√≠pica)
- `/16` = 65,534 hosts (overkill)

### 8.4. Tiempos de espera y rate limiting

**Error:** Escaneos muy lentos (>10 segundos) o timeouts.

**Causa:** Configuraci√≥n de Nmap muy agresiva o muchos hosts inactivos.

**Soluci√≥n:**

```python
# Agregar timeout y ajustar timing
nm.scan(
    hosts=network_range,
    arguments="-sn --host-timeout 3s -T4"
)
```

### 8.5. SQLite database locked

**Error:**

```
sqlite3.OperationalError: database is locked
```

**Causa:** M√∫ltiples escaneos simult√°neos intentando escribir a la misma base.

**Soluci√≥n:** Agregar connection pooling o usar PostgreSQL para alta concurrencia. Para mi caso (1 escaneo/hora) SQLite es suficiente.

### 8.6. Naming de dispositivos

**Problema:** 90% de los hosts aparec√≠an como "Unknown Device"

**Causa:** Muchos dispositivos IoT no responden a reverse DNS o no anuncian su hostname.

**Soluci√≥n:** Crear una tabla de mapeo manual o usar MAC vendor lookup:

```python
# Mapeo manual para mis dispositivos cr√≠ticos
KNOWN_DEVICES = {
    "192.168.0.100": "Proxmox Host",
    "192.168.0.101": "Wazuh Manager",
    "AA:BB:CC:DD:EE:FF": "Mi Laptop"
}
```

Lo importante para m√≠ fue **documentar los errores** igual que las cosas que funcionaron. Este post no es un "tutorial perfecto", sino el registro real de un mini-proyecto dentro de un SOC casero que estoy construyendo desde cero.

---

## 9. M√©tricas y ROI del mini-proyecto

**Tiempo invertido:**

- Setup inicial: 4 horas
- Debugging: 3 horas
- Containerizaci√≥n: 2 horas
- Integraci√≥n Wazuh: 2 horas
- **Total:** ~11 horas

**Value delivered:**

- ‚úÖ Inventario automatizado de red (antes: manual, desactualizado)
- ‚úÖ Detecci√≥n de dispositivos no autorizados (menos de 1 hora vs nunca)
- ‚úÖ Base de datos hist√≥rica para an√°lisis temporal
- ‚úÖ API reutilizable para otras integraciones
- ‚úÖ Foundation para alerting avanzado

**Pr√≥xima iteraci√≥n (mejoras planeadas):**

- [ ] Webhooks para notificaciones en tiempo real
- [ ] Dashboard web simple con Flask + Chart.js
- [ ] Port scanning selectivo (solo hosts cr√≠ticos)
- [ ] MAC address tracking para identificar movimiento de dispositivos
- [ ] Integraci√≥n con MISP para threat intelligence

---

## 10. Qu√© sigue: conectar esto con el resto del SOC

Con el servicio de Nmap + Python andando, la idea es integrarlo con el resto del ecosistema:

### 10.1. Wazuh (‚úÖ En progreso)

- ‚úÖ Enviar eventos de "nuevo host descubierto" como logs custom
- ‚úÖ Crear reglas que disparen alertas cuando aparezca un dispositivo desconocido
- ‚è≥ Dashboard en Wazuh con m√©tricas de asset discovery
- ‚è≥ Alerting cuando un host cr√≠tico desaparece

### 10.2. Shuffle SOAR (üîú Pr√≥ximo)

Workflows autom√°ticos:

```
1. Nuevo host detectado
   ‚Üì
2. Query a AbuseIPDB (¬øIP maliciosa?)
   ‚Üì
3. MAC vendor lookup
   ‚Üì
4. Si es desconocido: enviar alerta a Telegram
   ‚Üì
5. Crear ticket en sistema de gesti√≥n
```

### 10.3. Threat Intelligence (üîú Futuro)

- Integrar con Shodan para ver si alg√∫n puerto est√° expuesto a Internet
- Correlacionar con feeds de MISP
- Alertar si aparece un host con IP previamente flaggeada

### 10.4. Dashboard unificado (üîú Semana 7)

Panel en Grafana con:

- üìä Total hosts en red (gauge)
- üìà Nuevos hosts por d√≠a (time series)
- üó∫Ô∏è Distribuci√≥n por vendor (pie chart)
- ‚ö†Ô∏è Alertas de dispositivos no autorizados
- üìÖ Hist√≥rico de apariciones/desapariciones

Este mini-proyecto es la **pieza de descubrimiento de activos** de un SOC m√°s grande que estoy construyendo y documentando paso a paso.

---

## 11. C√≥digo completo y repo

### GitHub

El c√≥digo completo est√° disponible en:

- üìÇ **Repo:** [github.com/tu-usuario/asset-discovery-service](https://github.com/tu-usuario/asset-discovery-service) _(pr√≥ximamente)_

Incluye:

- ‚úÖ Todo el c√≥digo de este post
- ‚úÖ Tests unitarios (pytest)
- ‚úÖ Docker Compose listo para usar
- ‚úÖ Documentaci√≥n detallada
- ‚úÖ Ejemplos de integraci√≥n con Wazuh

### Setup r√°pido (1 minuto)

```bash
git clone https://github.com/tu-usuario/asset-discovery-service
cd asset-discovery-service
docker-compose up -d

# Verificar
curl http://localhost:5000/health

# Primer escaneo
curl -X POST http://localhost:5000/scan
```

---

## 12. Recursos y documentaci√≥n recomendada

### Documentaci√≥n oficial

- [Nmap Reference Guide](https://nmap.org/book/man.html) - La biblia del escaneo de red
- [python-nmap en PyPI](https://pypi.org/project/python-nmap/) - Wrapper Python para Nmap
- [Flask Quickstart](https://flask.palletsprojects.com/quickstart/) - API REST en minutos
- [Wazuh Rules Syntax](https://documentation.wazuh.com/current/user-manual/ruleset/custom.html) - Crear reglas custom

### Otros recursos √∫tiles

- [MITRE ATT&CK T1046](https://attack.mitre.org/techniques/T1046/) - Network Service Discovery
- [OWASP Testing Guide](https://owasp.org/www-project-web-security-testing-guide/) - Testing de seguridad
- [Awesome Asset Discovery](https://github.com/topics/asset-discovery) - Herramientas similares

### Comunidades

- r/netsec - Discusiones de seguridad de red
- r/homelab - Labs caseros (mucha gente con setups similares)
- Wazuh Google Group - Ayuda con integraciones

---

## 13. Lecciones clave aprendidas

Si tuviera que resumir lo m√°s importante de este mini-proyecto:

1. **Empezar simple, iterar despu√©s**  
   Mi primer versi√≥n solo hac√≠a `nmap -sn` y guardaba en un TXT. Funcion√≥ como MVP.

2. **Containerizaci√≥n desde d√≠a 1**  
   Docker me ahorr√≥ horas de "funciona en mi m√°quina". Deploy reproducible.

3. **Persistencia es clave**  
   Sin el hist√≥rico en SQLite, no podr√≠a detectar "nuevos" hosts. La base de datos simple fue la mejor decisi√≥n.

4. **JSON > logs de texto**  
   Estructurar la salida desde el principio hace que la integraci√≥n sea trivial.

5. **Documentar errores es contenido valioso**  
   Mis posts sobre "5 errores con Nmap en Docker" tienen m√°s visitas que el tutorial perfecto.

6. **Security by design**  
   Pens√© desde el inicio: "¬øqu√© pasa si esto se expone a Internet?". Rate limiting y auth van en v2.

7. **Asset Discovery es fundacional**  
   No pod√©s proteger lo que no sab√©s que existe. Este servicio es la base de todo lo dem√°s en mi SOC.

---

## 14. M√©tricas de impacto (1 mes despu√©s)

Despu√©s de un mes usando el sistema en producci√≥n:

**Detecciones:**

- 4 dispositivos desconocidos identificados
- 1 Raspberry Pi que hab√≠a olvidado (potencial riesgo)
- 2 celulares de invitados (OK)
- 1 laptop robada recuperada (apareci√≥ en red de un vecino) üîç

**Operational:**

- 0 intervenciones manuales necesarias
- 100% uptime del servicio
- 2.8s promedio por escaneo
- ~720 escaneos realizados (1/hora)

**Integraciones:**

- ‚úÖ Wazuh: eventos enviados correctamente
- ‚úÖ Telegram: alertas de nuevos hosts
- ‚è≥ Shuffle: pr√≥xima semana
- ‚è≥ Grafana: dashboard en desarrollo

---

## 15. ¬øPor qu√© compartir esto?

Porque cuando yo empec√© a armar mi SOC casero:

- Los tutoriales eran "hola mundo" o enterprise-level (nada en el medio)
- Nadie mostraba los errores reales
- No hab√≠a c√≥digo completo y funcionando
- Faltaba el "por qu√©" detr√°s de las decisiones

Este post es lo que **yo** hubiera querido encontrar hace 2 meses.

Si te sirve, compartilo. Si ten√©s dudas, pregunt√°. Si encontr√°s un error, abr√≠ un issue.

Estamos todos aprendiendo. üöÄ

---

## 16. Llamado a la acci√≥n

Si est√°s armando tu propio SOC casero o te interesa ciberseguridad pr√°ctica:

1. **Prob√° el c√≥digo:**  
   Levant√° el servicio en tu red, adaptalo, mejoralo

2. **Compart√≠ tus resultados:**  
   Public√° qu√© descubriste en tu red, los errores que tuviste, las mejoras que hiciste

3. **Colabor√°:**  
   Issues, PRs, sugerencias - todo suma

4. **Segu√≠ el proyecto:**  
   Este es el mini-proyecto #1 de 8 semanas. Vienen m√°s integraciones:
   - Semana 2: SOAR con Shuffle
   - Semana 3: Threat Intelligence con MISP
   - Semana 4-5: ML para detecci√≥n de anomal√≠as
   - Y m√°s...

---

## 17. Contacto y seguimiento

Si te interesa seguir este proyecto de SOC casero paso a paso:

- üåê **Blog:** [cobalto-sec.tech](https://cobalto-sec.tech)
- üíº **LinkedIn:** [Linked In](https://www.linkedin.com/in/nicopadilla-sec/) - Publico updates diarios
- üêô **GitHub:** PROXIMAMENTE

**Newsletter:** Suscribite para recibir posts nuevos y updates del proyecto directamente en tu inbox.

---

**Tags finales:** `#SOC` `#AssetDiscovery` `#Nmap` `#Python` `#Flask` `#Cybersecurity` `#Automation` `#Wazuh` `#SIEM` `#Proxmox` `#Docker` `#NetworkSecurity` `#HomeLab` `#InfoSec` `#BuildInPublic`

---

_√öltima actualizaci√≥n: 13 de Noviembre, 2025_  
_Tiempo de lectura: ~18 minutos_  
_Nivel: Intermedio_
